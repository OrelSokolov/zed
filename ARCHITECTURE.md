# Архитектура потока данных Ollama → Zed UI

## Схема потоков выполнения

```
┌─────────────────────────────────────────────────────────────────────────┐
│                          OLLAMA SERVER                                   │
│                    (localhost:11434)                                     │
│                    Отправляет JSON chunks                                │
│                    ~150 bytes каждые 50-100ms                            │
└────────────────────────────┬────────────────────────────────────────────┘
                              │ TCP Socket
                              │ (блокирующее чтение)
                              ▼
┌─────────────────────────────────────────────────────────────────────────┐
│  ПОТОК #1: std::thread::spawn (синхронный)                             │
│  ────────────────────────────────────────────────────────────────────  │
│  Файл: crates/ollama/src/ollama_direct.rs:77                           │
│                                                                          │
│  std::net::TcpStream::read() ──► блокируется на 50-100ms               │
│         │                                                               │
│         │ [150 bytes]                                                  │
│         ▼                                                               │
│  tx.try_send(Ok(data)) ──► НЕБЛОКИРУЮЩАЯ отправка                      │
└────────────────────────────┬────────────────────────────────────────────┘
                              │ smol::channel::unbounded
                              │ (канал между потоками)
                              ▼
┌─────────────────────────────────────────────────────────────────────────┐
│  ПОТОК #2: GPUI Foreground Executor (async, smol)                      │
│  ────────────────────────────────────────────────────────────────────  │
│                                                                          │
│  ┌──────────────────────────────────────────────────────────────────┐  │
│  │ 1. ollama_direct.rs:153                                          │  │
│  │    rx.recv().await ──► БЛОКИРУЕТСЯ на 50-100ms                   │  │
│  │    (ждет данных из канала)                                       │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    stream::unfold ──► парсит JSON строки                         │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    ChatResponseDelta                                              │  │
│  └────────────────────────┬──────────────────────────────────────────┘  │
│                            │ Stream<ChatResponseDelta>                    │
│                            ▼                                              │
│  ┌──────────────────────────────────────────────────────────────────┐  │
│  │ 2. language_models/provider/ollama.rs:510                        │  │
│  │    stream.flat_map() ──► преобразует в события                  │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    LanguageModelCompletionEvent (Text, ToolUse, etc.)             │  │
│  └────────────────────────┬──────────────────────────────────────────┘  │
│                            │ Stream<LanguageModelCompletionEvent>          │
│                            ▼                                              │
│  ┌──────────────────────────────────────────────────────────────────┐  │
│  │ 3. agent/src/thread.rs:1386                                     │  │
│  │    events.next().await ──► БЛОКИРУЕТСЯ на 50-100ms              │  │
│  │    (poll_time совпадает с временем чтения из канала)            │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    futures::select! ──► race с cancellation                     │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    this.update(cx, |this, cx| { ... }) ──► БЛОКИРУЕТ entity      │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    handle_completion_event() ──► обработка события                │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    event_stream.send_text() ──► отправка в UI                    │  │
│  └────────────────────────┬──────────────────────────────────────────┘  │
│                            │ mpsc::UnboundedSender<ThreadEvent>           │
│                            ▼                                              │
│  ┌──────────────────────────────────────────────────────────────────┐  │
│  │ 4. agent/src/agent.rs:963                                        │  │
│  │    events.next().await ──► получение из канала                   │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    acp_thread.update() ──► обновление UI                         │  │
│  └──────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────────────┘
```

## Точки задержки (bottlenecks)

### 1. **TCP Socket Read** (50-100ms)
   - **Где**: `std::thread` → `tcp_stream.read()`
   - **Почему**: Сервер отправляет данные маленькими порциями (~150 bytes)
   - **Блокирует**: Синхронный `read()` ждет данных

### 2. **Channel Receive** (50-100ms)
   - **Где**: `ollama_direct.rs:153` → `rx.recv().await`
   - **Почему**: Ждет данных из канала, которые приходят с задержкой
   - **Блокирует**: Async executor не может продолжить без данных

### 3. **Stream Poll** (50-100ms)
   - **Где**: `agent/thread.rs:1386` → `events.next().await`
   - **Почему**: `poll_time` совпадает с временем чтения из канала
   - **Блокирует**: Executor ждет следующего события из стрима

### 4. **Entity Update** (0ms, но может блокировать)
   - **Где**: `agent/thread.rs:1413` → `this.update(cx, |this, cx| { ... })`
   - **Почему**: Обновление entity может блокировать, если entity уже обновляется
   - **Блокирует**: Другие обновления того же entity

## Сравнение с test_ollama2

### test_ollama2 (быстро, 120-170 токенов/сек)
```
Ollama Server ──► std::net::TcpStream::read() ──► обработка в главном потоке
                    (синхронно, без планировщика)
```

### Zed (медленно, 20 токенов/сек)
```
Ollama Server ──► std::thread ──► smol::channel ──► async executor ──► entity updates
                    (50ms)         (50ms)           (50ms)              (0ms)
```

## Проблема

**Все задержки накапливаются:**
- TCP read: 50-100ms
- Channel recv: 50-100ms (совпадает с TCP read)
- Stream poll: 50-100ms (совпадает с channel recv)

**Итого**: Каждое событие обрабатывается с задержкой 50-100ms вместо мгновенной обработки.

## Почему test_ollama2 быстрее?

1. **Нет async планировщика** - синхронный `read()` в главном потоке
2. **Нет каналов** - данные обрабатываются напрямую
3. **Нет entity updates** - нет блокировок на обновлении состояния
4. **Нет stream polling** - данные обрабатываются сразу после чтения

## Архитектура LMStudio (БЫСТРО, 170 токенов/сек)

```
┌─────────────────────────────────────────────────────────────────────────┐
│                          LMSTUDIO SERVER                                │
│                    (localhost:1234)                                      │
│                    Отправляет SSE chunks                                │
│                    ~256 bytes каждые 5-10ms                             │
└────────────────────────────┬────────────────────────────────────────────┘
                              │ HTTP через reqwest
                              │ (Tokio runtime)
                              ▼
┌─────────────────────────────────────────────────────────────────────────┐
│  ПОТОК: GPUI Foreground Executor (async, smol)                          │
│  ────────────────────────────────────────────────────────────────────  │
│                                                                          │
│  ┌──────────────────────────────────────────────────────────────────┐  │
│  │ 1. reqwest_client.rs:264                                        │  │
│  │    response.bytes_stream() ──► Tokio stream                     │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    .into_async_read() ──► адаптер Tokio → smol                  │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    AsyncBody::from_reader(bytes)                                 │  │
│  └────────────────────────┬──────────────────────────────────────────┘  │
│                            │ AsyncBody (async read)                        │
│                            ▼                                              │
│  ┌──────────────────────────────────────────────────────────────────┐  │
│  │ 2. lmstudio.rs:445                                               │  │
│  │    body.read(&mut chunk[256]).await ──► НЕ БЛОКИРУЕТСЯ!          │  │
│  │    (читает напрямую из async body, без каналов)                 │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    stream::unfold ──► парсит SSE строки                          │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    ResponseStreamEvent                                            │  │
│  └────────────────────────┬──────────────────────────────────────────┘  │
│                            │ Stream<ResponseStreamEvent>                  │
│                            ▼                                              │
│  ┌──────────────────────────────────────────────────────────────────┐  │
│  │ 3. language_models/provider/lmstudio.rs:489                      │  │
│  │    events.flat_map() ──► преобразует в события                  │  │
│  │         │                                                         │  │
│  │         ▼                                                         │  │
│  │    LanguageModelCompletionEvent                                  │  │
│  └────────────────────────┬──────────────────────────────────────────┘  │
│                            │ Stream<LanguageModelCompletionEvent>         │
│                            ▼                                              │
│  ┌──────────────────────────────────────────────────────────────────┐  │
│  │ 4. agent/src/thread.rs:1386                                     │  │
│  │    events.next().await ──► БЫСТРО! (5-10ms)                     │  │
│  │    (данные уже в буфере, нет задержки)                           │  │
│  └──────────────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────────────┘
```

## Ключевые различия LMStudio vs Ollama

### LMStudio (БЫСТРО)
1. ✅ **Использует reqwest_client** → Tokio runtime
2. ✅ **`bytes_stream().into_async_read()`** → правильный адаптер Tokio → smol
3. ✅ **Читает напрямую из AsyncBody** → `body.read()` в async контексте
4. ✅ **НЕТ отдельного потока** → нет задержки от каналов
5. ✅ **НЕТ межрантаймовой задержки** → `into_async_read()` правильно адаптирует потоки
6. ✅ **Буфер 256 байт** → оптимальный размер

### Ollama (МЕДЛЕННО - текущая реализация)
1. ❌ **Отдельный std::thread** → добавляет задержку
2. ❌ **smol::channel** → добавляет задержку между потоками
3. ❌ **rx.recv().await** → блокируется на 50-100ms
4. ❌ **Попытка обойти межрантаймовую задержку** → создала еще больше задержки!

### Ollama (старая реализация через reqwest)
1. ✅ Использовала `reqwest_client` как LMStudio
2. ❌ Но почему-то была медленнее (возможно, из-за `BufReader::lines()`)

## Почему LMStudio не страдает от проблемы?

### 1. **Правильный адаптер потоков**
```rust
// reqwest_client.rs:264
let bytes = response
    .bytes_stream()           // Tokio stream
    .map_err(futures::io::Error::other)
    .into_async_read();       // ✅ Правильный адаптер Tokio → smol
```
`into_async_read()` правильно адаптирует Tokio stream в async read, который работает эффективно в smol executor.

### 2. **Нет дополнительных каналов**
LMStudio читает напрямую из `AsyncBody`:
```rust
// lmstudio.rs:445
body.read(&mut chunk[256]).await  // ✅ Прямое чтение, без каналов
```

### 3. **Оптимальный размер буфера**
```rust
let mut chunk = [0u8; 256];  // ✅ 256 байт - оптимальный размер
```

### 4. **Эффективная обработка SSE**
LMStudio использует SSE формат, который легче парсить:
```
data: {"content": "..."}
data: {"content": "..."}
```
vs Ollama JSON lines:
```
{"message": {"content": "..."}}
{"message": {"content": "..."}}
```

## Решение для Ollama

**Вернуться к использованию reqwest_client** (как LMStudio), но:
1. Убрать `BufReader::lines()` (уже сделано)
2. Использовать `body.read()` напрямую (уже сделано)
3. Убрать отдельный поток с каналом (вернуться к reqwest)
4. Использовать `bytes_stream().into_async_read()` (как LMStudio)

**Ключевой момент**: Попытка обойти межрантаймовую задержку через отдельный поток **создала еще больше задержки**! Нужно использовать правильный адаптер `into_async_read()`, который уже есть в reqwest_client.

